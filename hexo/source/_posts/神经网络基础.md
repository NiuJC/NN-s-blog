# 神经网络

### 反向传播

##### 损失函数

回归问题

- MAE损失

- MSE损失

- Smooth-L1损失

分类问题

- 交叉熵损失函数
- 

##### 梯度

##### 梯度下降

- 批量梯度下降（BGD）

- 随机梯度下降（SGD）

- 小批量梯度下降

  存在的问题：

  1. 容易陷入局部最优
  2. 学习率不变

  解决方案：

  1. 动量https://blog.csdn.net/liuy9803

  2. 自适应学习率

     随着训练的进行学习率应该越来越小

     Adagrad

     Adam

     Nadam(Adam+NAG)

### 前向传播

##### 网络搭建

##### 激活函数

- Sigmod
- Tanh
- ReLU
- LeakyReLU
- ELU
- swish
- softmax

